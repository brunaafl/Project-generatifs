{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-10T14:55:24.856211Z",
     "start_time": "2025-03-10T14:55:15.430932Z"
    }
   },
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import argparse\n",
    "\n",
    "from data import get_dataset, get_dataloader\n",
    "from denoisers.DnCNN.get_dncnn import create_model_DnCNN\n",
    "from denoisers.hierarquicalVAE.get_VAE import create_model_nvae\n",
    "from guided_diffusion.unet import create_model\n",
    "from guided_diffusion.gaussian_diffusion import create_sampler\n",
    "from util.img_utils import clear_color\n",
    "from tasks import create_operator\n",
    "from gibbs_sampler import GibbsSampler\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunalopes/PycharmProjects/PnP-SGS-Project/PnP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/brunalopes/PycharmProjects/PnP-SGS-Project/gibbs_sampler/__init__.py:41: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if sampler is None and model_type is 'DDMP':\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check device\n",
    "device_str = \"cuda:\" if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_str)"
   ],
   "id": "8f87b5c6449134ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Here, we will focus on gaussian blur operator\n",
    "operator_config = {\n",
    "    \"name\": \"gaussian_blur\",\n",
    "    \"kernel_size\": 61,\n",
    "    \"intensity\": 3.0,\n",
    "    \"channels\": 3,\n",
    "    \"img_dim\": 256\n",
    "}\n",
    "\n",
    "# Create the linear operator\n",
    "H_gaussian = create_operator(**operator_config, device=device)\n"
   ],
   "id": "599db9d1a3fdc2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get the test dataset\n",
    "get_dataset(\"ffhq\", root=\"data/samples_ffhq\")\n",
    "dataset = get_dataset(\"ffhq\", root=\"data/samples_ffhq\")\n",
    "num_test_images = len(dataset)\n",
    "dataloader = get_dataloader(dataset, batch_size=1, num_workers=0, train=False)"
   ],
   "id": "809f9fb5c757d6dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## With DDMP model as a denoiser",
   "id": "90f204a663529ca7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Select configurations for the sampler in the case of diffusion\n",
    "diffusion_config = {\n",
    "    \"sampler\": \"ddpm\",\n",
    "    \"steps\": 1000,\n",
    "    \"noise_schedule\": \"linear\",\n",
    "    \"model_mean_type\": \"epsilon\",\n",
    "    \"model_var_type\": \"learned_range\",\n",
    "    \"dynamic_threshold\": False,\n",
    "    \"clip_denoised\": True,\n",
    "    \"rescale_timesteps\": False,\n",
    "    \"timestep_respacing\": 1000\n",
    "}\n",
    "\n",
    "# Create sampler to be used in the case of diffusion\n",
    "diffusion_sampler = create_sampler(**diffusion_config)"
   ],
   "id": "8049e15970f79d10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Now, get the pre-trained diffusion model\n",
    "possible_diffusion_models = {'ffhq_10m':'models/ffhq_10m.pt', 'imagenet':'models/imagenet256.pt'}\n",
    "\n",
    "# Base configurations\n",
    "\n",
    "model_config = {\n",
    "    \"image_size\": 256,\n",
    "    \"num_channels\": 128,\n",
    "    \"num_res_blocks\": 1,\n",
    "    \"channel_mult\": \"\",\n",
    "    \"learn_sigma\": True,\n",
    "    \"class_cond\": False,\n",
    "    \"use_checkpoint\": False,\n",
    "    \"attention_resolutions\": 16,\n",
    "    \"num_heads\": 4,\n",
    "    \"num_head_channels\": 64,\n",
    "    \"num_heads_upsample\": -1,\n",
    "    \"use_scale_shift_norm\": True,\n",
    "    \"dropout\": 0.0,\n",
    "    \"resblock_updown\": True,\n",
    "    \"use_fp16\": False,\n",
    "    \"use_new_attention_order\": False,\n",
    "    \"model_path\": possible_diffusion_models['ffhq_10m'] # With ffhq_10m\n",
    "}\n",
    "\n",
    "# Init and loag pretrained model, and put in inference mode\n",
    "model_type = 'DDMP'\n",
    "model_DDMP = create_model(**model_config)\n",
    "model_DDMP.to(device)\n",
    "model_DDMP.eval()"
   ],
   "id": "785e1f7d622062da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sample\n",
    "\n",
    "In here, we use the fact that we divide our problem in (1) sampling x such that x is close to z and (2) sampling z as a denoised image"
   ],
   "id": "37c8410b29d839c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Lets see with just one test sample\n",
    "X = next(iter(dataloader)).to(device)\n",
    "\n",
    "Y = H_gaussian.forward(X)\n",
    "sigma = torch.tensor(0.05).to(device)\n",
    "# Creating the noisy image Y = HX + n\n",
    "Y = Y + sigma*torch.randn(X.shape).to(device)\n",
    "\n",
    "# Plot noisy image\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "ax.imshow(clear_color(Y))\n",
    "ax.set_title('Noisy image')\n",
    "ax.axis('off')\n",
    "plt.savefig(f\"results/image_noisy.png\", dpi=200, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "607a6744cbfd4445"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Execute sampling\n",
    "N_bi = 20  # Burn-in itereations (Discart)\n",
    "N_MC = 23  # Total number of iterations\n",
    "gibbs = GibbsSampler(\n",
    "                     Y=Y,\n",
    "                     sigma=sigma,\n",
    "                     operator=H_gaussian,\n",
    "                     sampler=diffusion_sampler,\n",
    "                     model=model_DDMP,\n",
    "                     model_type=model_type,\n",
    "                     device=device,\n",
    "                     N_MC=23,\n",
    "                     N_bi=20,\n",
    "                     rho=0.1,\n",
    "                     rho_decay_rate=0.8,\n",
    "                     plot_process = 5)\n",
    "\n",
    "X_MC, Z_MC = gibbs.run()\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 20))\n",
    "\n",
    "axes[0].imshow(clear_color(X))\n",
    "axes[0].set_title('True image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(clear_color(Y))\n",
    "axes[1].set_title('Noisy image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(clear_color(torch.mean(Z_MC[:,:,:,N_bi:N_MC], axis=-1)))\n",
    "axes[2].set_title('Z Reconstructed image')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(clear_color(torch.mean(X_MC[:,:,:,N_bi:N_MC], axis=-1)))\n",
    "axes[3].set_title('X Reconstructed image')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.savefig(f\"results/example_test.png\", dpi=200, bbox_inches='tight')"
   ],
   "id": "d9c93863782b9522"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comparing with the output after one diffusion step back\n",
    "\n",
    "Here, we are estimating the noise level of the original image Y, and then passing it to backward diffusion to recover an estimative of X"
   ],
   "id": "dfa57fba4d8030f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5a631f02a3192d59"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
